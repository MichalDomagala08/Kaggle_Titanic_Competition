{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TITANIC_PATH = os.path.join(\"C:\\\\Users\\\\barak\\\\Documents\\\\GitHub\\\\\\Kaggle_Titanic_Competition\",\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd178c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3a786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f2bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.Survived\n",
    "X = train_data.drop(['Survived'],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val , y_train, y_val= train_test_split(X,y,test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de48df88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "# To szybka klasa która robi i zamienia dane kategoryczne na numeryczne\n",
    "# Zamieniamy na dane numeryczne ABC i jeśli chcemy zamienic na numeryczne to bierzemy one hot encode\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75afd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Imputer wypełnia dane na odstawie tej Strategoo\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\",'Pclass',])),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75128972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09469253, -1.58243582],\n",
       "       [-0.50564033,  0.80969646],\n",
       "       [-0.09469253,  0.80969646],\n",
       "       ...,\n",
       "       [-0.09469253, -1.58243582],\n",
       "       [-1.01932508,  0.80969646],\n",
       "       [-0.09469253,  0.80969646]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b396c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "\n",
    "# Szybka klasa która wylicza najczęściej występujacy element itp\n",
    "# \n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47c19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector(['Embarked','Name','Sex','Ticket','Cabin'])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dfe499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc079c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Mamy tutaj Feature Union którea łączy nasze cechy  i pipelien'y\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0514dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e5e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\barak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        FeatureUnion(transformer_list=[('num_pipeline',\n",
       "                                                                        Pipeline(steps=[('select_numeric',\n",
       "                                                                                         DataFrameSelector(attribute_names=['Age',\n",
       "                                                                                                                            'Pclass'])),\n",
       "                                                                                        ('scaler',\n",
       "                                                                                         StandardScaler()),\n",
       "                                                                                        ('imputer',\n",
       "                                                                                         SimpleImputer(strategy='median'))])),\n",
       "                                                                       ('cat_pipeline',\n",
       "                                                                        Pipeline(steps=[('select_cat',\n",
       "                                                                                         DataFrameSelector(attribute_names=['Embarked',\n",
       "                                                                                                                            'Name',\n",
       "                                                                                                                            'Sex',\n",
       "                                                                                                                            'Ticket',\n",
       "                                                                                                                            'Cabin'])),\n",
       "                                                                                        ('imputer',\n",
       "                                                                                         MostFrequentImputer()),\n",
       "                                                                                        ('cat_encoder',\n",
       "                                                                                         OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                       sparse=False))]))])),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid={'classifier__C': [0.001, 0.01, 0.03, 0.1, 0.3, 1, 10,\n",
       "                                           100]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC predictors\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_1 = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline), \n",
    "    ('classifier', SVC(kernel='rbf'))])\n",
    "pipe_2 = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline), \n",
    "    ('classifier', SVC(kernel='poly'))])\n",
    "pipe_3 = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline), \n",
    "    ('classifier', SVC(kernel='linear'))])\n",
    "pipe_4 = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline), \n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__gamma': [0.001,0.003, 0.01,0.03, 0.1,0.3, 1, 10, 100,200],\n",
    "            'classifier__C': [0.001,0.003, 0.01, 0.03, 0.1,0.3, 1, 10, 100,200]\n",
    "}\n",
    "param_grid_2 = {\n",
    "            'classifier__C': [0.001, 0.01 ,0.03, 0.1,0.3, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe_1, param_grid, cv=kfold)\n",
    "grid_2 = GridSearchCV(pipe_2, param_grid, cv=kfold)\n",
    "grid_3 = GridSearchCV(pipe_3, param_grid, cv=kfold)\n",
    "grid_4 = GridSearchCV(pipe_4, param_grid_2, cv=kfold)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_4.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97818ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_rbf 1.0\n",
      "SVC_poly 1.0\n",
      "SVC_rbf 1.0\n",
      "LogReg 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "preds = [(grid_1.best_estimator_,'SVC_rbf'),(grid_2.best_estimator_,'SVC_poly'),(grid_3.best_estimator_,'SVC_rbf'),(grid_4.best_estimator_,'LogReg')]\n",
    "\n",
    "for clf,name in preds:\n",
    "    clf.fit(X_val, y_val)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    print(name, accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f89650",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_1 = grid_1.best_estimator_.predict(test_data)\n",
    "prediction_2= grid_2.best_estimator_.predict(test_data)\n",
    "prediction_3= grid_3.best_estimator_.predict(test_data)\n",
    "prediction_4= grid_4.best_estimator_.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3692b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data=np.vstack([prediction_1,prediction_2,prediction_3,prediction_4]).T\n",
    "prediction_1 = np.vstack([np.arange(len(X_train)+1,len(X_train)+len(prediction_1)+1,1),prediction_1]).T\n",
    "prediction_2 = np.vstack([np.arange(len(X_train)+1,len(X_train)+len(prediction_1)+1,1),prediction_2]).T\n",
    "prediction_3 = np.vstack([np.arange(len(X_train)+1,len(X_train)+len(prediction_1)+1,1),prediction_3]).T\n",
    "prediction_4 = np.vstack([np.arange(len(X_train)+1,len(X_train)+len(prediction_1)+1,1),prediction_4]).T\n",
    "df_prediction_1 = pd.DataFrame(prediction_1,columns=['PassengerId','Survived'])\n",
    "df_prediction_2 = pd.DataFrame(prediction_2,columns=['PassengerId','Survived'])\n",
    "df_prediction_3 = pd.DataFrame(prediction_3,columns=['PassengerId','Survived'])\n",
    "df_prediction_4 = pd.DataFrame(prediction_4,columns=['PassengerId','Survived'])\n",
    "\n",
    "\n",
    "df_prediction_1.to_csv(os.path.join(\"C:\\\\Users\\\\barak\\\\Documents\\\\GitHub\\\\\\Kaggle_Titanic_Competition\\\\Results\",'SVC_rbf.csv'),index=False) # BEST ONE SO FAR\n",
    "df_prediction_2.to_csv(os.path.join(\"C:\\\\Users\\\\barak\\\\Documents\\\\GitHub\\\\\\Kaggle_Titanic_Competition\\\\Results\",'SVC_poly.csv'),index=False)\n",
    "df_prediction_3.to_csv(os.path.join(\"C:\\\\Users\\\\barak\\\\Documents\\\\GitHub\\\\\\Kaggle_Titanic_Competition\\\\Results\",'SVC_lin.csv'),index=False)\n",
    "df_prediction_4.to_csv(os.path.join(\"C:\\\\Users\\\\barak\\\\Documents\\\\GitHub\\\\\\Kaggle_Titanic_Competition\\\\Results\",'LogReg.csv'),index=False)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1232c12b",
   "metadata": {},
   "source": [
    "Best one:  **SVM**:\n",
    "+ kernel: rbf\n",
    "+ C = 100\n",
    "+ gamma = 0.01\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76efd8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 FeatureUnion(transformer_list=[('num_pipeline',\n",
       "                                                 Pipeline(steps=[('select_numeric',\n",
       "                                                                  DataFrameSelector(attribute_names=['Age',\n",
       "                                                                                                     'Pclass'])),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler()),\n",
       "                                                                 ('imputer',\n",
       "                                                                  SimpleImputer(strategy='median'))])),\n",
       "                                                ('cat_pipeline',\n",
       "                                                 Pipeline(steps=[('select_cat',\n",
       "                                                                  DataFrameSelector(attribute_names=['Embarked',\n",
       "                                                                                                     'Name',\n",
       "                                                                                                     'Sex',\n",
       "                                                                                                     'Ticket',\n",
       "                                                                                                     'Cabin'])),\n",
       "                                                                 ('imputer',\n",
       "                                                                  MostFrequentImputer()),\n",
       "                                                                 ('cat_encoder',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                sparse=False))]))])),\n",
       "                ('classifier', SVC(C=100, gamma=0.01))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa79ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>712</td>\n",
       "      <td>1</td>\n",
       "      <td>Klaber, Mr. Herman</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113028</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>662</td>\n",
       "      <td>3</td>\n",
       "      <td>Badt, Mr. Mohamed</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2623</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>Bissette, Miss. Amelia</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17760</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>C99</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>287</td>\n",
       "      <td>3</td>\n",
       "      <td>de Mulder, Mr. Theodore</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345774</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Mrs. Joseph (Juliette Marie Louise La...</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>638</td>\n",
       "      <td>2</td>\n",
       "      <td>Collyer, Mr. Harvey</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 31921</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>632</td>\n",
       "      <td>3</td>\n",
       "      <td>Lundahl, Mr. Johan Svensson</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347743</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Meyer, Mr. Edgar Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17604</td>\n",
       "      <td>82.1708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>719</td>\n",
       "      <td>3</td>\n",
       "      <td>McEvoy, Mr. Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36568</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "711          712       1                                 Klaber, Mr. Herman   \n",
       "32            33       3                           Glynn, Miss. Mary Agatha   \n",
       "661          662       3                                  Badt, Mr. Mohamed   \n",
       "269          270       1                             Bissette, Miss. Amelia   \n",
       "286          287       3                            de Mulder, Mr. Theodore   \n",
       "..           ...     ...                                                ...   \n",
       "608          609       2  Laroche, Mrs. Joseph (Juliette Marie Louise La...   \n",
       "637          638       2                                Collyer, Mr. Harvey   \n",
       "631          632       3                        Lundahl, Mr. Johan Svensson   \n",
       "34            35       1                            Meyer, Mr. Edgar Joseph   \n",
       "718          719       3                                McEvoy, Mr. Michael   \n",
       "\n",
       "        Sex   Age  SibSp  Parch         Ticket      Fare Cabin Embarked  \n",
       "711    male   NaN      0      0         113028   26.5500  C124        S  \n",
       "32   female   NaN      0      0         335677    7.7500   NaN        Q  \n",
       "661    male  40.0      0      0           2623    7.2250   NaN        C  \n",
       "269  female  35.0      0      0       PC 17760  135.6333   C99        S  \n",
       "286    male  30.0      0      0         345774    9.5000   NaN        S  \n",
       "..      ...   ...    ...    ...            ...       ...   ...      ...  \n",
       "608  female  22.0      1      2  SC/Paris 2123   41.5792   NaN        C  \n",
       "637    male  31.0      1      1     C.A. 31921   26.2500   NaN        S  \n",
       "631    male  51.0      0      0         347743    7.0542   NaN        S  \n",
       "34     male  28.0      1      0       PC 17604   82.1708   NaN        C  \n",
       "718    male   NaN      0      0          36568   15.5000   NaN        Q  \n",
       "\n",
       "[179 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be3b129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>Woolner, Mr. Hugh</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19947</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>C52</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>377</td>\n",
       "      <td>3</td>\n",
       "      <td>Landergren, Miss. Aurora Adelia</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C 7077</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>356</td>\n",
       "      <td>3</td>\n",
       "      <td>Vanden Steen, Mr. Leo Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345783</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>Penasco y Castellana, Mrs. Victor de Satode (M...</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C65</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>Spedden, Mrs. Frederic Oakley (Margaretta Corn...</td>\n",
       "      <td>female</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16966</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>E34</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>417</td>\n",
       "      <td>2</td>\n",
       "      <td>Drew, Mrs. James Vivian (Lulu Thorne Christian)</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28220</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>458</td>\n",
       "      <td>1</td>\n",
       "      <td>Kenyon, Mrs. Frederick R (Marion)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17464</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>D21</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>644</td>\n",
       "      <td>3</td>\n",
       "      <td>Foo, Mr. Choong</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "55            56       1                                  Woolner, Mr. Hugh   \n",
       "376          377       3                    Landergren, Miss. Aurora Adelia   \n",
       "355          356       3                        Vanden Steen, Mr. Leo Peter   \n",
       "307          308       1  Penasco y Castellana, Mrs. Victor de Satode (M...   \n",
       "319          320       1  Spedden, Mrs. Frederic Oakley (Margaretta Corn...   \n",
       "..           ...     ...                                                ...   \n",
       "416          417       2    Drew, Mrs. James Vivian (Lulu Thorne Christian)   \n",
       "556          557       1  Duff Gordon, Lady. (Lucille Christiana Sutherl...   \n",
       "457          458       1                  Kenyon, Mrs. Frederick R (Marion)   \n",
       "111          112       3                               Zabour, Miss. Hileni   \n",
       "643          644       3                                    Foo, Mr. Choong   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket      Fare Cabin Embarked  \n",
       "55     male   NaN      0      0     19947   35.5000   C52        S  \n",
       "376  female  22.0      0      0    C 7077    7.2500   NaN        S  \n",
       "355    male  28.0      0      0    345783    9.5000   NaN        S  \n",
       "307  female  17.0      1      0  PC 17758  108.9000   C65        C  \n",
       "319  female  40.0      1      1     16966  134.5000   E34        C  \n",
       "..      ...   ...    ...    ...       ...       ...   ...      ...  \n",
       "416  female  34.0      1      1     28220   32.5000   NaN        S  \n",
       "556  female  48.0      1      0     11755   39.6000   A16        C  \n",
       "457  female   NaN      1      0     17464   51.8625   D21        S  \n",
       "111  female  14.5      1      0      2665   14.4542   NaN        C  \n",
       "643    male   NaN      0      0      1601   56.4958   NaN        S  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1f1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = preprocess_pipeline.transform(X_val)\n",
    "X_train = preprocess_pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f745542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.DataFrame(X_val)\n",
    "X_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caa5572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1398</th>\n",
       "      <th>1399</th>\n",
       "      <th>1400</th>\n",
       "      <th>1401</th>\n",
       "      <th>1402</th>\n",
       "      <th>1403</th>\n",
       "      <th>1404</th>\n",
       "      <th>1405</th>\n",
       "      <th>1406</th>\n",
       "      <th>1407</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.505640</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.848097</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.727203</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.316255</td>\n",
       "      <td>-0.386370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1.275133</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>-1.019325</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 1408 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1     2     3     4     5     6     7     8     9     ...  \\\n",
       "0   -0.094693 -1.582436   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1   -0.505640  0.809696   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2   -0.094693  0.809696   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3   -0.848097 -1.582436   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4    0.727203 -1.582436   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "..        ...       ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "707  0.316255 -0.386370   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "708  1.275133 -1.582436   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "709 -0.094693 -1.582436   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "710 -1.019325  0.809696   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "711 -0.094693  0.809696   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "     1398  1399  1400  1401  1402  1403  1404  1405  1406  1407  \n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "707   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "708   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "709   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "710   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "711   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "\n",
       "[712 rows x 1408 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca44bf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1398</th>\n",
       "      <th>1399</th>\n",
       "      <th>1400</th>\n",
       "      <th>1401</th>\n",
       "      <th>1402</th>\n",
       "      <th>1403</th>\n",
       "      <th>1404</th>\n",
       "      <th>1405</th>\n",
       "      <th>1406</th>\n",
       "      <th>1407</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.727203</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.384747</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042290</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-0.505640</td>\n",
       "      <td>-0.386370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.110781</td>\n",
       "      <td>-0.386370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.480607</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>-1.582436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 1408 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1     2     3     4     5     6     7     8     9     ...  \\\n",
       "0   -0.094693 -1.582436   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1   -0.094693  0.809696   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2    0.727203  0.809696   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3    0.384747 -1.582436   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4    0.042290  0.809696   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "..        ...       ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "174 -0.505640 -0.386370   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "175  0.110781 -0.386370   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "176  1.480607  0.809696   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "177 -0.094693 -1.582436   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "178 -0.094693  0.809696   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "     1398  1399  1400  1401  1402  1403  1404  1405  1406  1407  \n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "174   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "175   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "176   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "177   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "178   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "\n",
       "[179 rows x 1408 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce54f10",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c5f938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 4000)              5636000   \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 4000)             16000     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2000)              8002000   \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 2000)             8000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1000)              2001000   \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1000)             4000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 500)              2000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 250)               125250    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 250)              1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,296,001\n",
      "Trainable params: 16,280,501\n",
      "Non-trainable params: 15,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.8701 - accuracy: 0.6980 - val_loss: 0.6559 - val_accuracy: 0.7598\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2722 - accuracy: 0.9073 - val_loss: 0.6488 - val_accuracy: 0.6872\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1067 - accuracy: 0.9761 - val_loss: 0.6340 - val_accuracy: 0.6592\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0332 - accuracy: 0.9958 - val_loss: 0.6310 - val_accuracy: 0.6536\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0211 - accuracy: 0.9986 - val_loss: 0.6401 - val_accuracy: 0.6313\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.6201\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 0.5978\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.6957 - val_accuracy: 0.5810\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.5810\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 9.5772e-04 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.5810\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 8.4350e-04 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.5810\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 6.9023e-04 - accuracy: 1.0000 - val_loss: 0.8368 - val_accuracy: 0.5810\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 5.3763e-04 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.5810\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 7.5819e-04 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.5810\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 4.2936e-04 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.5810\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 6.3766e-04 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.5810\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 4.2241e-04 - accuracy: 1.0000 - val_loss: 1.0173 - val_accuracy: 0.5810\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 3.7147e-04 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.5810\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 3.0963e-04 - accuracy: 1.0000 - val_loss: 1.0792 - val_accuracy: 0.5810\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 3.1325e-04 - accuracy: 1.0000 - val_loss: 1.1079 - val_accuracy: 0.5810\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 2.6436e-04 - accuracy: 1.0000 - val_loss: 1.1359 - val_accuracy: 0.5810\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 2.9542e-04 - accuracy: 1.0000 - val_loss: 1.1627 - val_accuracy: 0.5810\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 2.2039e-04 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.5810\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 2.1892e-04 - accuracy: 1.0000 - val_loss: 1.2147 - val_accuracy: 0.5810\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 3.0477e-04 - accuracy: 1.0000 - val_loss: 1.2424 - val_accuracy: 0.5810\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 1.9769e-04 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.5810\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.8735e-04 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.5810\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.7804e-04 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.5810\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 3.3615e-04 - accuracy: 1.0000 - val_loss: 1.3360 - val_accuracy: 0.5810\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.6884e-04 - accuracy: 1.0000 - val_loss: 1.3559 - val_accuracy: 0.5810\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 2.1037e-04 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.5810\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 2.2652e-04 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.5810\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.5028e-04 - accuracy: 1.0000 - val_loss: 1.4177 - val_accuracy: 0.5810\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.4917e-04 - accuracy: 1.0000 - val_loss: 1.4360 - val_accuracy: 0.5810\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.7488e-04 - accuracy: 1.0000 - val_loss: 1.4544 - val_accuracy: 0.5810\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.7810e-04 - accuracy: 1.0000 - val_loss: 1.4702 - val_accuracy: 0.5810\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 2.0765e-04 - accuracy: 1.0000 - val_loss: 1.4854 - val_accuracy: 0.5810\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.5987e-04 - accuracy: 1.0000 - val_loss: 1.5007 - val_accuracy: 0.5810\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.3523e-04 - accuracy: 1.0000 - val_loss: 1.5157 - val_accuracy: 0.5810\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.3724e-04 - accuracy: 1.0000 - val_loss: 1.5292 - val_accuracy: 0.5810\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.4053e-04 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.5810\n",
      "Epoch 42/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 109ms/step - loss: 1.1684e-04 - accuracy: 1.0000 - val_loss: 1.5554 - val_accuracy: 0.5810\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 1.3151e-04 - accuracy: 1.0000 - val_loss: 1.5695 - val_accuracy: 0.5810\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.3356e-04 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.5810\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.2994e-04 - accuracy: 1.0000 - val_loss: 1.5934 - val_accuracy: 0.5810\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.2839e-04 - accuracy: 1.0000 - val_loss: 1.6043 - val_accuracy: 0.5810\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 1.1793e-04 - accuracy: 1.0000 - val_loss: 1.6143 - val_accuracy: 0.5810\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.8093e-04 - accuracy: 1.0000 - val_loss: 1.6234 - val_accuracy: 0.5810\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.4763e-04 - accuracy: 1.0000 - val_loss: 1.6359 - val_accuracy: 0.5810\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.0024e-04 - accuracy: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.5810\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 1.0392e-04 - accuracy: 1.0000 - val_loss: 1.6552 - val_accuracy: 0.5810\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0632e-04 - accuracy: 1.0000 - val_loss: 1.6632 - val_accuracy: 0.5810\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.0370e-04 - accuracy: 1.0000 - val_loss: 1.6701 - val_accuracy: 0.5810\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1.2815e-04 - accuracy: 1.0000 - val_loss: 1.6813 - val_accuracy: 0.5810\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.0187e-04 - accuracy: 1.0000 - val_loss: 1.6912 - val_accuracy: 0.5810\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.0984e-04 - accuracy: 1.0000 - val_loss: 1.6983 - val_accuracy: 0.5810\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 8.8084e-05 - accuracy: 1.0000 - val_loss: 1.7039 - val_accuracy: 0.5810\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 1.0266e-04 - accuracy: 1.0000 - val_loss: 1.7101 - val_accuracy: 0.5810\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 9.5303e-05 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.5810\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.0127e-04 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.5810\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 7.8890e-05 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.5810\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 8.4727e-05 - accuracy: 1.0000 - val_loss: 1.7325 - val_accuracy: 0.5810\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 9.1961e-05 - accuracy: 1.0000 - val_loss: 1.7370 - val_accuracy: 0.5810\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.2736e-04 - accuracy: 1.0000 - val_loss: 1.7433 - val_accuracy: 0.5810\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 8.0587e-05 - accuracy: 1.0000 - val_loss: 1.7469 - val_accuracy: 0.5810\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 8.0152e-05 - accuracy: 1.0000 - val_loss: 1.7509 - val_accuracy: 0.5810\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 7.7874e-05 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.5810\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 9.2728e-05 - accuracy: 1.0000 - val_loss: 1.7587 - val_accuracy: 0.5810\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 7.1416e-05 - accuracy: 1.0000 - val_loss: 1.7629 - val_accuracy: 0.5810\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 7.3139e-05 - accuracy: 1.0000 - val_loss: 1.7652 - val_accuracy: 0.5810\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 7.1444e-05 - accuracy: 1.0000 - val_loss: 1.7677 - val_accuracy: 0.5810\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 6.6621e-05 - accuracy: 1.0000 - val_loss: 1.7694 - val_accuracy: 0.5810\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 8.4231e-05 - accuracy: 1.0000 - val_loss: 1.7706 - val_accuracy: 0.5810\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 8.4137e-05 - accuracy: 1.0000 - val_loss: 1.7700 - val_accuracy: 0.5810\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 7.3802e-05 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.5810\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 6.5004e-05 - accuracy: 1.0000 - val_loss: 1.7694 - val_accuracy: 0.5810\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.3574e-04 - accuracy: 1.0000 - val_loss: 1.7716 - val_accuracy: 0.5810\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 8.0687e-05 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.5810\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 6.8150e-05 - accuracy: 1.0000 - val_loss: 1.7705 - val_accuracy: 0.5810\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 6.9024e-05 - accuracy: 1.0000 - val_loss: 1.7690 - val_accuracy: 0.5810\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 6.0244e-05 - accuracy: 1.0000 - val_loss: 1.7678 - val_accuracy: 0.5810\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 6.5261e-05 - accuracy: 1.0000 - val_loss: 1.7649 - val_accuracy: 0.5810\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 6.0871e-05 - accuracy: 1.0000 - val_loss: 1.7632 - val_accuracy: 0.5810\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 5.9958e-05 - accuracy: 1.0000 - val_loss: 1.7609 - val_accuracy: 0.5810\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 6.7690e-05 - accuracy: 1.0000 - val_loss: 1.7575 - val_accuracy: 0.5810\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 6.2282e-05 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.5810\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 5.6480e-05 - accuracy: 1.0000 - val_loss: 1.7516 - val_accuracy: 0.5810\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 6.2082e-05 - accuracy: 1.0000 - val_loss: 1.7467 - val_accuracy: 0.5810\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 6.1418e-05 - accuracy: 1.0000 - val_loss: 1.7436 - val_accuracy: 0.5810\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 5.4009e-05 - accuracy: 1.0000 - val_loss: 1.7399 - val_accuracy: 0.5810\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 6.0195e-05 - accuracy: 1.0000 - val_loss: 1.7348 - val_accuracy: 0.5810\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 5.3579e-05 - accuracy: 1.0000 - val_loss: 1.7298 - val_accuracy: 0.5810\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 5.5568e-05 - accuracy: 1.0000 - val_loss: 1.7262 - val_accuracy: 0.5810\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 6.8467e-05 - accuracy: 1.0000 - val_loss: 1.7201 - val_accuracy: 0.5810\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 7.8610e-05 - accuracy: 1.0000 - val_loss: 1.7180 - val_accuracy: 0.5810\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 8.0640e-05 - accuracy: 1.0000 - val_loss: 1.7155 - val_accuracy: 0.5810\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 4.7121e-05 - accuracy: 1.0000 - val_loss: 1.7118 - val_accuracy: 0.5810\n",
      "Epoch 98/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 108ms/step - loss: 4.9075e-05 - accuracy: 1.0000 - val_loss: 1.7073 - val_accuracy: 0.5810\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 7.1473e-05 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.5810\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 5.1123e-05 - accuracy: 1.0000 - val_loss: 1.6956 - val_accuracy: 0.5810\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 5.4747e-05 - accuracy: 1.0000 - val_loss: 1.6889 - val_accuracy: 0.5810\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 4.5534e-05 - accuracy: 1.0000 - val_loss: 1.6825 - val_accuracy: 0.5810\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 4.6942e-05 - accuracy: 1.0000 - val_loss: 1.6754 - val_accuracy: 0.5810\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 8.7209e-05 - accuracy: 1.0000 - val_loss: 1.6664 - val_accuracy: 0.5810\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 4.6867e-05 - accuracy: 1.0000 - val_loss: 1.6589 - val_accuracy: 0.5810\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 5.0682e-05 - accuracy: 1.0000 - val_loss: 1.6525 - val_accuracy: 0.5810\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 4.5341e-05 - accuracy: 1.0000 - val_loss: 1.6434 - val_accuracy: 0.5810\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 4.4498e-05 - accuracy: 1.0000 - val_loss: 1.6348 - val_accuracy: 0.5810\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 4.9063e-05 - accuracy: 1.0000 - val_loss: 1.6246 - val_accuracy: 0.5810\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 4.1586e-05 - accuracy: 1.0000 - val_loss: 1.6166 - val_accuracy: 0.5810\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 6.3047e-05 - accuracy: 1.0000 - val_loss: 1.6097 - val_accuracy: 0.5810\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 5.7461e-05 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.5810\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 4.5368e-05 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.5810\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 5.0940e-05 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.5810\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 7.4198e-05 - accuracy: 1.0000 - val_loss: 1.5681 - val_accuracy: 0.5810\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 5.6276e-05 - accuracy: 1.0000 - val_loss: 1.5556 - val_accuracy: 0.5866\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 4.5877e-05 - accuracy: 1.0000 - val_loss: 1.5436 - val_accuracy: 0.5866\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 4.0033e-05 - accuracy: 1.0000 - val_loss: 1.5335 - val_accuracy: 0.5866\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 4.0171e-05 - accuracy: 1.0000 - val_loss: 1.5226 - val_accuracy: 0.5866\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 6.4550e-05 - accuracy: 1.0000 - val_loss: 1.5108 - val_accuracy: 0.5866\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 3.7276e-05 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.5866\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 4.0899e-05 - accuracy: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.5922\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 4.1646e-05 - accuracy: 1.0000 - val_loss: 1.4805 - val_accuracy: 0.5922\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 3.5266e-05 - accuracy: 1.0000 - val_loss: 1.4691 - val_accuracy: 0.6034\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 3.3467e-05 - accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 0.6034\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 3.6228e-05 - accuracy: 1.0000 - val_loss: 1.4446 - val_accuracy: 0.6145\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 4.0525e-05 - accuracy: 1.0000 - val_loss: 1.4314 - val_accuracy: 0.6201\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 3.3331e-05 - accuracy: 1.0000 - val_loss: 1.4184 - val_accuracy: 0.6201\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 3.4221e-05 - accuracy: 1.0000 - val_loss: 1.4058 - val_accuracy: 0.6201\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 3.2577e-05 - accuracy: 1.0000 - val_loss: 1.3926 - val_accuracy: 0.6201\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 4.7277e-05 - accuracy: 1.0000 - val_loss: 1.3812 - val_accuracy: 0.6201\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 3.6300e-05 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.6257\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 4.6402e-05 - accuracy: 1.0000 - val_loss: 1.3552 - val_accuracy: 0.6369\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 3.3511e-05 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.6369\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 3.2290e-05 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.6425\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 4.0298e-05 - accuracy: 1.0000 - val_loss: 1.3139 - val_accuracy: 0.6425\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 3.1968e-05 - accuracy: 1.0000 - val_loss: 1.3009 - val_accuracy: 0.6425\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 3.2721e-05 - accuracy: 1.0000 - val_loss: 1.2868 - val_accuracy: 0.6425\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 4.2143e-05 - accuracy: 1.0000 - val_loss: 1.2731 - val_accuracy: 0.6480\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 3.1783e-05 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.6480\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 3.6300e-05 - accuracy: 1.0000 - val_loss: 1.2453 - val_accuracy: 0.6536\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 2.9972e-05 - accuracy: 1.0000 - val_loss: 1.2322 - val_accuracy: 0.6592\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 3.9576e-05 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.6592\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 4.1140e-05 - accuracy: 1.0000 - val_loss: 1.2062 - val_accuracy: 0.6592\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 3.3033e-05 - accuracy: 1.0000 - val_loss: 1.1946 - val_accuracy: 0.6592\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 3.8996e-05 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.6648\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 3.4448e-05 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.6704\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 3.2051e-05 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.6816\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 4.7706e-05 - accuracy: 1.0000 - val_loss: 1.1461 - val_accuracy: 0.6927\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 2.7408e-05 - accuracy: 1.0000 - val_loss: 1.1349 - val_accuracy: 0.6927\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 3.2482e-05 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.6927\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 2.9668e-05 - accuracy: 1.0000 - val_loss: 1.1127 - val_accuracy: 0.7095\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 3.4759e-05 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.7095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.6751e-05 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.7095\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 2.6975e-05 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.7095\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 2.7831e-05 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.7095\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2.7132e-05 - accuracy: 1.0000 - val_loss: 1.0556 - val_accuracy: 0.7095\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 4.1555e-05 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.7151\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 2.8134e-05 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.7095\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 3.2946e-05 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.7095\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2.9580e-05 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.7151\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 3.5540e-05 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.7151\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 3.0997e-05 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.7430\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.8496e-05 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.7486\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2.9002e-05 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.7542\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 2.4023e-05 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.7654\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.5391e-05 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.7654\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 2.7379e-05 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.7709\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 3.3640e-05 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.7709\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 2.3679e-05 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.7709\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.3300e-05 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.7709\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 2.7532e-05 - accuracy: 1.0000 - val_loss: 0.9250 - val_accuracy: 0.7765\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 3.4848e-05 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.7765\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 2.3560e-05 - accuracy: 1.0000 - val_loss: 0.9148 - val_accuracy: 0.7821\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 4.1148e-05 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.7821\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 2.8705e-05 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7821\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.9429e-05 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.7821\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.5587e-05 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.7821\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 3.6701e-05 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.7821\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 2.1659e-05 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7821\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 2.6044e-05 - accuracy: 1.0000 - val_loss: 0.8849 - val_accuracy: 0.7821\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 2.5413e-05 - accuracy: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.7877\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.4681e-05 - accuracy: 1.0000 - val_loss: 0.8785 - val_accuracy: 0.7989\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.3085e-05 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.8045\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.2135e-05 - accuracy: 1.0000 - val_loss: 0.8721 - val_accuracy: 0.7989\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.1495e-05 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.7989\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.5310e-05 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.7989\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 3.0422e-05 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.7989\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 2.6783e-05 - accuracy: 1.0000 - val_loss: 0.8638 - val_accuracy: 0.7989\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 2.4211e-05 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.7989\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 2.4083e-05 - accuracy: 1.0000 - val_loss: 0.8599 - val_accuracy: 0.8045\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 2.4358e-05 - accuracy: 1.0000 - val_loss: 0.8581 - val_accuracy: 0.8045\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.4969e-05 - accuracy: 1.0000 - val_loss: 0.8571 - val_accuracy: 0.8101\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 2.0462e-05 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.8156\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 2.0687e-05 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.8156\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 2.1421e-05 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.8156\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 2.0289e-05 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8156\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 3.7898e-05 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.8212\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 2.4380e-05 - accuracy: 1.0000 - val_loss: 0.8519 - val_accuracy: 0.8212\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.9801e-05 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8268\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.8774e-05 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8268\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 2.0301e-05 - accuracy: 1.0000 - val_loss: 0.8529 - val_accuracy: 0.8268\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 2.3069e-05 - accuracy: 1.0000 - val_loss: 0.8528 - val_accuracy: 0.8268\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 2.2192e-05 - accuracy: 1.0000 - val_loss: 0.8528 - val_accuracy: 0.8268\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 2.1117e-05 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.8324\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.7906e-05 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.8324\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 2.0866e-05 - accuracy: 1.0000 - val_loss: 0.8552 - val_accuracy: 0.8324\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.8872e-05 - accuracy: 1.0000 - val_loss: 0.8558 - val_accuracy: 0.8324\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 2.0601e-05 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.9952e-05 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.8324\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 2.6842e-05 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.8324\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 2.3255e-05 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.8324\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 2.0376e-05 - accuracy: 1.0000 - val_loss: 0.8598 - val_accuracy: 0.8324\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.9179e-05 - accuracy: 1.0000 - val_loss: 0.8606 - val_accuracy: 0.8324\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.9212e-05 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.8324\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 2.1380e-05 - accuracy: 1.0000 - val_loss: 0.8616 - val_accuracy: 0.8324\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.7195e-05 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.8324\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.6727e-05 - accuracy: 1.0000 - val_loss: 0.8628 - val_accuracy: 0.8324\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 1.6459e-05 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.8324\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.7460e-05 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.8324\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 2.5181e-05 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.8324\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.6989e-05 - accuracy: 1.0000 - val_loss: 0.8638 - val_accuracy: 0.8324\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 2.1585e-05 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.8324\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.9407e-05 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.8324\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.9211e-05 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.8324\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.7072e-05 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.8324\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.7027e-05 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.8324\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 4.7132e-05 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.8380\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.7189e-05 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.8380\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.8360e-05 - accuracy: 1.0000 - val_loss: 0.8657 - val_accuracy: 0.8380\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 2.0633e-05 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.8380\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.7979e-05 - accuracy: 1.0000 - val_loss: 0.8686 - val_accuracy: 0.8380\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.5221e-05 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.8380\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.6725e-05 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.8380\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.7795e-05 - accuracy: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.8380\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1.8246e-05 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.8380\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.5557e-05 - accuracy: 1.0000 - val_loss: 0.8737 - val_accuracy: 0.8380\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.8177e-05 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.8380\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.8003e-05 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.8380\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.5127e-05 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.8380\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.9915e-05 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.8380\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.8525e-05 - accuracy: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.8380\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.5053e-05 - accuracy: 1.0000 - val_loss: 0.8784 - val_accuracy: 0.8380\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.7605e-05 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.8380\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.4411e-05 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.8380\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.6723e-05 - accuracy: 1.0000 - val_loss: 0.8815 - val_accuracy: 0.8380\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.5003e-05 - accuracy: 1.0000 - val_loss: 0.8820 - val_accuracy: 0.8380\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.7050e-05 - accuracy: 1.0000 - val_loss: 0.8825 - val_accuracy: 0.8380\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.4878e-05 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.8380\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.4318e-05 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8380\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.5757e-05 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.8380\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 2.4857e-05 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.8380\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.3994e-05 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.8380\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.4868e-05 - accuracy: 1.0000 - val_loss: 0.8863 - val_accuracy: 0.8380\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.3721e-05 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.8380\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.5561e-05 - accuracy: 1.0000 - val_loss: 0.8877 - val_accuracy: 0.8380\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.9704e-05 - accuracy: 1.0000 - val_loss: 0.8878 - val_accuracy: 0.8380\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.6300e-05 - accuracy: 1.0000 - val_loss: 0.8882 - val_accuracy: 0.8380\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.7012e-05 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.8380\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.5334e-05 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.8380\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.8949e-05 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.8380\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 3.3901e-05 - accuracy: 1.0000 - val_loss: 0.8900 - val_accuracy: 0.8380\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.4920e-05 - accuracy: 1.0000 - val_loss: 0.8906 - val_accuracy: 0.8380\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.2831e-05 - accuracy: 1.0000 - val_loss: 0.8912 - val_accuracy: 0.8380\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 1.6956e-05 - accuracy: 1.0000 - val_loss: 0.8919 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 1.2818e-05 - accuracy: 1.0000 - val_loss: 0.8924 - val_accuracy: 0.8380\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.2380e-05 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.8380\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.6701e-05 - accuracy: 1.0000 - val_loss: 0.8937 - val_accuracy: 0.8380\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.4558e-05 - accuracy: 1.0000 - val_loss: 0.8950 - val_accuracy: 0.8380\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.4039e-05 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.8380\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.2144e-05 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.8380\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 1.2721e-05 - accuracy: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.8380\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.2516e-05 - accuracy: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.8380\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.2499e-05 - accuracy: 1.0000 - val_loss: 0.8968 - val_accuracy: 0.8380\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.5383e-05 - accuracy: 1.0000 - val_loss: 0.8979 - val_accuracy: 0.8380\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.4423e-05 - accuracy: 1.0000 - val_loss: 0.8988 - val_accuracy: 0.8380\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.1638e-05 - accuracy: 1.0000 - val_loss: 0.8992 - val_accuracy: 0.8380\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.5476e-05 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.8380\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.2238e-05 - accuracy: 1.0000 - val_loss: 0.8996 - val_accuracy: 0.8380\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.3572e-05 - accuracy: 1.0000 - val_loss: 0.8997 - val_accuracy: 0.8380\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 2.0664e-05 - accuracy: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.8380\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.2782e-05 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.8380\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.3914e-05 - accuracy: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.8380\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.4604e-05 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.8380\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 1.7150e-05 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.8380\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.1000e-05 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8380\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.7711e-05 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.8380\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 1.1561e-05 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.8380\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 1.5458e-05 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.8380\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.6294e-05 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.8380\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.1511e-05 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.8380\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.7039e-05 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.8380\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.6001e-05 - accuracy: 1.0000 - val_loss: 0.9073 - val_accuracy: 0.8380\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.6501e-05 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.8380\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.2069e-05 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.8380\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.1888e-05 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.8380\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.2839e-05 - accuracy: 1.0000 - val_loss: 0.9111 - val_accuracy: 0.8380\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.0888e-05 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.8380\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.1303e-05 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.8380\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.1667e-05 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.8380\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.6758e-05 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.8380\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 1.1196e-05 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.8380\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.3797e-05 - accuracy: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.8380\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.3935e-05 - accuracy: 1.0000 - val_loss: 0.9145 - val_accuracy: 0.8380\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.2643e-05 - accuracy: 1.0000 - val_loss: 0.9161 - val_accuracy: 0.8380\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.3702e-05 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.8380\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.3654e-05 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.8380\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.0083e-05 - accuracy: 1.0000 - val_loss: 0.9190 - val_accuracy: 0.8380\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.0613e-05 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.8380\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.0314e-05 - accuracy: 1.0000 - val_loss: 0.9195 - val_accuracy: 0.8380\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.0114e-05 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.8380\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.5279e-05 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.8380\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0972e-05 - accuracy: 1.0000 - val_loss: 0.9208 - val_accuracy: 0.8380\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.0105e-05 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.8380\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.0936e-05 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.8380\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.3206e-05 - accuracy: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.8380\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.2954e-05 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8380\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.2040e-05 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.8380\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0953e-05 - accuracy: 1.0000 - val_loss: 0.9209 - val_accuracy: 0.8380\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.3717e-05 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.8380\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0134e-05 - accuracy: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 9.9885e-06 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.8380\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 9.5049e-06 - accuracy: 1.0000 - val_loss: 0.9206 - val_accuracy: 0.8380\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 9.8466e-06 - accuracy: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.8380\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.0403e-05 - accuracy: 1.0000 - val_loss: 0.9209 - val_accuracy: 0.8380\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 9.9791e-06 - accuracy: 1.0000 - val_loss: 0.9213 - val_accuracy: 0.8380\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.0959e-05 - accuracy: 1.0000 - val_loss: 0.9214 - val_accuracy: 0.8380\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.1446e-05 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.8380\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.3986e-05 - accuracy: 1.0000 - val_loss: 0.9216 - val_accuracy: 0.8380\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 9.4108e-06 - accuracy: 1.0000 - val_loss: 0.9216 - val_accuracy: 0.8380\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 9.6398e-06 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.8380\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 9.2229e-06 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.8380\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 9.9049e-06 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.8380\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0052e-05 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.8380\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 9.2164e-06 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.8380\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.1978e-05 - accuracy: 1.0000 - val_loss: 0.9218 - val_accuracy: 0.8380\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.0570e-05 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.8380\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.1068e-05 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.8380\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 8.6957e-06 - accuracy: 1.0000 - val_loss: 0.9229 - val_accuracy: 0.8380\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.2227e-05 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.8380\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.0640e-05 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.8380\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.0087e-05 - accuracy: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.8380\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.0894e-05 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.8380\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 1.0071e-05 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.8380\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.1699e-05 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.8380\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.4439e-05 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.8380\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 9.9962e-06 - accuracy: 1.0000 - val_loss: 0.9258 - val_accuracy: 0.8380\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 9.7784e-06 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.8380\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.1187e-05 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.8380\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.2850e-05 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.8380\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.2889e-05 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.8380\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 9.3176e-06 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.8380\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0291e-05 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.8380\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.1721e-05 - accuracy: 1.0000 - val_loss: 0.9274 - val_accuracy: 0.8380\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.2857e-05 - accuracy: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.8380\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.1856e-05 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.8380\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.1413e-05 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.8380\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 9.7131e-06 - accuracy: 1.0000 - val_loss: 0.9298 - val_accuracy: 0.8380\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 9.0246e-06 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.8380\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.1672e-05 - accuracy: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.8380\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 9.2541e-06 - accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.8380\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 8.1632e-06 - accuracy: 1.0000 - val_loss: 0.9314 - val_accuracy: 0.8380\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.4919e-05 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.8380\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 8.6237e-06 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.8380\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.0609e-05 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.8380\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 9.0544e-06 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.8380\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.4035e-05 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.8380\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 9.7755e-06 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.8380\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 8.3381e-06 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.8380\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 9.7208e-06 - accuracy: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.8380\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.0283e-05 - accuracy: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.8380\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 9.1727e-06 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.8380\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.3869e-05 - accuracy: 1.0000 - val_loss: 0.9358 - val_accuracy: 0.8380\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 9.2309e-06 - accuracy: 1.0000 - val_loss: 0.9365 - val_accuracy: 0.8380\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 8.4542e-06 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.8380\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.1338e-05 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.8380\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 7.6809e-06 - accuracy: 1.0000 - val_loss: 0.9391 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.1478e-05 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.8380\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.3688e-05 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.8380\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 7.4984e-06 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.8380\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 8.0091e-06 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.8380\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.3756e-05 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.8380\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 9.1582e-06 - accuracy: 1.0000 - val_loss: 0.9423 - val_accuracy: 0.8380\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.4574e-05 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.8380\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 7.6477e-06 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.8380\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.4742e-05 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.8380\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 8.4678e-06 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.8380\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 8.4059e-06 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.8380\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 8.9087e-06 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.8380\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 7.4515e-06 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.8380\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 8.1696e-06 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.8380\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 9.4901e-06 - accuracy: 1.0000 - val_loss: 0.9478 - val_accuracy: 0.8380\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.3814e-05 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.8380\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 7.9633e-06 - accuracy: 1.0000 - val_loss: 0.9467 - val_accuracy: 0.8380\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.1376e-05 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.8380\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 7.8422e-06 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.8380\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 7.8389e-06 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.8380\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 8.2421e-06 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.8380\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 9.6407e-06 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.8380\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0480e-05 - accuracy: 1.0000 - val_loss: 0.9467 - val_accuracy: 0.8380\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 7.3584e-06 - accuracy: 1.0000 - val_loss: 0.9474 - val_accuracy: 0.8380\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 8.5664e-06 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.8380\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 8.7794e-06 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.8380\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 7.3914e-06 - accuracy: 1.0000 - val_loss: 0.9474 - val_accuracy: 0.8380\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.6339e-05 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.8380\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 6.8361e-06 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.8380\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 7.6245e-06 - accuracy: 1.0000 - val_loss: 0.9474 - val_accuracy: 0.8380\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 7.4546e-06 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.8380\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.1751e-05 - accuracy: 1.0000 - val_loss: 0.9481 - val_accuracy: 0.8380\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 8.5900e-06 - accuracy: 1.0000 - val_loss: 0.9488 - val_accuracy: 0.8380\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 7.4171e-06 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.8380\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 9.5439e-06 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.8380\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 6.9836e-06 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.8380\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 8.8309e-06 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.8380\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 6.6146e-06 - accuracy: 1.0000 - val_loss: 0.9504 - val_accuracy: 0.8380\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 7.0140e-06 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.8380\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 6.8549e-06 - accuracy: 1.0000 - val_loss: 0.9512 - val_accuracy: 0.8380\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 7.5796e-06 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.8380\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 7.2375e-06 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.8380\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 6.6141e-06 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.8380\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.1476e-05 - accuracy: 1.0000 - val_loss: 0.9522 - val_accuracy: 0.8380\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.0329e-05 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.8380\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 8.8886e-06 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 0.8380\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.6952e-05 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.8380\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 8.7386e-06 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.8380\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 8.1862e-06 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.8380\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 6.4197e-06 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.8380\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 6.5066e-06 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.8380\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 7.0467e-06 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.8380\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 1.0610e-05 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.8380\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 7.1041e-06 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.8380\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 8.6696e-06 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.8380\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 1.1143e-05 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 5.9314e-06 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.8380\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 6.7070e-06 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.8380\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.6069e-05 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.8380\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 8.1510e-06 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.8380\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 6.1573e-06 - accuracy: 1.0000 - val_loss: 0.9618 - val_accuracy: 0.8380\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 7.1593e-06 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.8380\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 9.6387e-06 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.8380\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 6.7871e-06 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.8380\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 7.4341e-06 - accuracy: 1.0000 - val_loss: 0.9631 - val_accuracy: 0.8380\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 6.0518e-06 - accuracy: 1.0000 - val_loss: 0.9630 - val_accuracy: 0.8380\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 7.6922e-06 - accuracy: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.8380\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 9.5347e-06 - accuracy: 1.0000 - val_loss: 0.9631 - val_accuracy: 0.8380\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.1328e-05 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.8380\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 6.3825e-06 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.8380\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 8.8821e-06 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.8380\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 6.4516e-06 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.8380\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 7.9870e-06 - accuracy: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.8380\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 7.0084e-06 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.8380\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 6.8955e-06 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.8380\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 6.8121e-06 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.8380\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 5.9181e-06 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.8380\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 9.6090e-06 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.8380\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.0563e-05 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.8380\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 7.7257e-06 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.8380\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 9.0162e-06 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.8380\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 6.2442e-06 - accuracy: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.8380\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 5.6510e-06 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.8380\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 5.7275e-06 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.8380\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.1907e-05 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.8380\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 5.6688e-06 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.8380\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 8.5975e-06 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.8380\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 6.3593e-06 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.8380\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 5.6033e-06 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.8380\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 6.1293e-06 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.8380\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.4125e-05 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.8380\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 5.3826e-06 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.8380\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 6.2258e-06 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.8380\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 6.2443e-06 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.8380\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 7.2393e-06 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.8380\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 5.1878e-06 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.8380\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 6.4148e-06 - accuracy: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.8380\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 5.8063e-06 - accuracy: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.8380\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 9.5168e-06 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.8380\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 5.4153e-06 - accuracy: 1.0000 - val_loss: 0.9700 - val_accuracy: 0.8380\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 6.3383e-06 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.8380\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 5.7365e-06 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.8380\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 5.8485e-06 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.8380\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 5.6878e-06 - accuracy: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.8380\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 5.3779e-06 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.8380\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 5.4782e-06 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.8380\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 7.4666e-06 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.8380\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 6.9333e-06 - accuracy: 1.0000 - val_loss: 0.9689 - val_accuracy: 0.8380\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.1991e-05 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.8380\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 5.8233e-06 - accuracy: 1.0000 - val_loss: 0.9689 - val_accuracy: 0.8380\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 5.5825e-06 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.8380\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 5.1967e-06 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 5.7710e-06 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.8380\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 7.0157e-06 - accuracy: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.8380\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 6.3391e-06 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.8380\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 5.3268e-06 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.8380\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 5.5574e-06 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.8380\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 5.8045e-06 - accuracy: 1.0000 - val_loss: 0.9727 - val_accuracy: 0.8380\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 5.9672e-06 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.8380\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 5.0044e-06 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.8380\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 6.2190e-06 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.8380\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 5.4410e-06 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.8380\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 4.9880e-06 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.8380\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9742 - accuracy: 0.8380\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NEXT Pipeline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4000,activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2000,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1000,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(250,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, validation_data= (X_val, y_val), batch_size=256, epochs=500)\n",
    "\n",
    "model.evaluate(X_val,y_val)\n",
    "\n",
    "from sklearn import  metrics\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9191b62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8435754189944135"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true= y_val, y_pred= (model.predict(X_val)  > 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35248900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "\n",
    "predictions = model.predict(X_test) >0.5\n",
    "\n",
    "prediction_5 = np.vstack([np.arange(len(train_data)+1,len(train_data)+len(predictions)+1,1),predictions.T]).T\n",
    "prediction_5 = pd.DataFrame(prediction_5,columns=['PassengerId','Survived'])\n",
    "prediction_5.to_csv(os.path.join(\"C:\\\\Users\\\\barak\\\\Documents\\\\GitHub\\\\Kaggle_Titanic_Competition\\\\Results\",'MLP_1.csv'),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "393017ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f635af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79ce45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
